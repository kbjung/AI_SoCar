{"cells":[{"cell_type":"markdown","metadata":{"id":"nDkE0N2TpAUr"},"source":["## Assignment 3. 이미지 기반 쏘카 차량 파손 인식을 위한 Semantic Segmentation 모델 Fine-tuning\n","\n","이번 과제에서는 7주차에 배운 Semnatic Segmentation 을 이용하여 실제 이미지 기반 차량 파손 인식 모델을 학습 시켜보겠습니다. \\\n","사용하게될 데이터는 쏘카에서 수집한 차량 파손 이미지와 파손된 위치에 대한 label입니다. \\\n","학습시킬 모델은 input 으로 차량 이미지를 받아서 output 으로 파손된 위치의 mask 를 내보내는 semantic segmentation 모델입니다.\n","\n","실습시간에 다뤘던 보행자 데이터와 달리, 차량 파손 이미지는 semantic segmentation pretrained model 에 학습되지 않은 class 를 예측해야합니다. 따라서 모델에 대한 fine-tuning 이 필수적입니다. \\\n","이런 실제 데이터에 대한 모델의 fine-tuning 을 직접 성공시켜보는 것이 이번 과제의 목표입니다. \n","\n","과제를 성공적으로 수행하기 위한 단계들은 다음과 같습니다. \\\n","먼저 기본적으로 pretrained model 을 불러와서 주어진 데이터에 fine-tuning 하는 방법을 알고 구현할 수 있어야 됩니다. \\\n","이 과정에서 어떤 pretrained model 을 쓸지, 어떻게 fine-tuning 을 할지도 고민해볼 수 있겠습니다. \n","\n","또한 이전 과제들에서 했던 것처럼 각종 hyper parameter 들을 어떻게 설정할 것인지, data 전처리는 어떻게 할 것인지 등의 고민을 통해 최적의 모델 세팅을 찾아내어 성능을 향상시킬 수도 있을 것입니다. \n","\n","주어진 기본 코드에서 여러가지 시도를 해보면서 좋은 차량 파손 인식 모델을 만들어봅시다.\n","\n","\n","### 1. Dataset\n","\n","이번 과제에서 다루게 될 데이터는 쏘카에서 수집한 차량 파손 이미지입니다.\n","\n","- 데이터의 종류\n","파손의 종류는 scratch로 파손에 대한 이미지와 mask 가 따로 주어집니다. \\\n","즉, 하나의 mask에서는 background 와 해당 파손이 표시가 되어 있습니다. \\\n","따라서 이번 과제에서는 scratch에 대한 semantic segmentation 모델을 학습하는 것을 목표로 하겠습니다. \\\n","모델들은 파손과 background를 binary classification 을 하는 모델이 되겠습니다. \n","\n","- Data split\n","각 데이터는 train/valid/test 세가지로 나뉘어 있습니다. \\\n","train 데이터는 200 개로 적게 주어졌습니다. 이를 잘 활용해서 fine-tuning 을 해봅시다. \\\n","이 분류는 임의로 수정하지 않도록 합시다. \n","\n","- 데이터의 형식\n","실습시간에 다뤘던 데이터와 달리 이번 과제에서 사용하는 mask 는 .jpg 형식의 RGB 이미지입니다. \\\n","PIL Image.open 으로 열어볼 경우 background 는 (0,0,0), 흰색 마스크는 (255,255,255)의 값을 가집니다. \\\n","따라서 DataLoader에서 해당 부분을 수정하여 기본 코드로 제공해드리니 확인하시길 바랍니다. \n","\n","\n","### 2. Model Structure\n","\n","Pretrained semantic segmentation 모델을 import, 데이터에 맞게 fine-tuning 을 하는 방법을 기본으로 하겠습니다. \\\n","어떠한 pretrained model을 사용할 것인지, fine-tuning 은 어떻게 할 것인지에 대해 고민해보고 직접 구현해봅시다. \n","\n","(Optional) 적절한 모델을 직접 설계해서 학습시켜보는 것도 도전해보는 것도 좋습니다! \n","\n","\n","### 3. 성능 측정\n","\n","이번 과제의 모델 성능은 모델의 meanIoU 로 측정하겠습니다. \\\n","meanIoU 의 경우 실습시간에 코드로 다루진 않았었는데, 기본 Trainer 코드에 meanIoU 계산 함수 뼈대와 출력에 대해서 제공하였습니다. \\\n","다만 meanIoU 함수에서 간단한 빈칸이 있어서 이를 직접 작성하셔야 함수가 작동이 될 것입니다.\\\n","meanIoU의 개념을 잘 이해하셨다면 쉽게 작성하실 수 있을테니 걱정하지마세요! \n","\n","\n","### 4. Hyperparameter Tuning 및 기타 세팅\n","\n","Learning rate 조절, batch size 조절, optimizer 선택, feature size 조절 등의 hyperparamter tuning 은 어떤 딥러닝 모델을 다룰 때나 고려해야하는 사항입니다. \\\n","또한 데이터 전처리 과정에서 data augmentation 등을 활용하여 학습 성능을 높여볼 수도 있겠습니다. \n","\n","이번 과제의 경우 MNIST 데이터와는 다르게 데이터 사이즈도 크고 모델도 커서 학습에 많은 시간이 걸릴 것입니다. \\\n","딥러닝이 오래 걸린다는 것을 체감해보실 수 있을텐데요, 이러한 시간적 제약도 고려하여 효율적으로 좋은 세팅을 찾아봅시다. \n","\n","\n","### 5. Display Setting\n","\n","이번 과제에서 다룰 모델은 학습시간이 상당히 오래 걸려서 epoch 단위로 모델의 성능을 display 하는 것은 너무 텀이 길 수 있습니다. \\\n","이를 해결하기 위해 몇 step 단위로 성능을 print 해주는 코드를 추가하여 제공해드리니 확인해봅시다. \n","\n","또한 성능에 대한 그래프와 모델의 parameter 도 학습이 다 끝나고 보여주고 저장하는 것도 좋지 않은 생각입니다. \\\n","학습시간이 길어지면 그 사이 코드가 끊긴다든지하는 위험이 존재하기 때문이죠. 잘못하다간 몇시간 고생한 것을 날려버릴 수도 있습니다. \\\n","그래서 epoch 단위로 현재까지의 성능 그래프와 현재 모델의 parameter 를 저장하는 코드를 Trainer에 추가하였으니 확인해봅시다. \\\n","이 때 모델을 저장하는 부분의 코드 역시 간단한 빈칸을 직접 작성해봅시다. \n","\n","\n","### 6. 좋은 예시 찾아보기\n","\n","모델의 학습이 완료되고 meanIoU 값이 잘 나왔다면 학습이 성공적이었다는 것이겠죠? \\\n","그렇지만 semantic segmentation 의 경우 직접 예시들을 visulaize 해봐야 얼마나 잘 학습이 됐는지 느끼실 수 있을겁니다. \\\n","그래서 test set 에서 성공적인 예시를 하나 이상 찾아서 visualize 해봅시다. \n","\n","[ 이미지, ground truth, prediction ]\n","\n","이렇게 3개의 이미지를 하나에 figure 에 띄워서 visualize 하는 코드를 직접 작성해봅시다. \n","\n","\n","### 7. Advanced Solution\n","\n","직접 test set 에서 실험해보시면 mean IoU 값을 보고 기대했던것보다 좋은 예시를 찾기 어려울 수도 있습니다.\\\n","이는 데이터에서 background 와 scratch 의 비중이 차이가 나서 생기는 문제입니다. \\\n","예를 들어 모델이 전부 background 로만 예측 하더라도 test 데이터에서도 background 의 비중이 크기 때문에 숫자만 보면 얼추 성능이 좋아보이게 나옵니다. 하지만 우리가 원하는 것은 scratch 예측이니 바람직한 결과가 아닙니다. \\\n","이러한 문제는 meanIoU 만이 아니라 각 class 별 IoU 를 확인해봄으로써 예측해볼 수 있습니다. \\\n","이렇게 class 별로 데이터의 양이 차이가 나는 문제를 \"Imbalanced data\" 에 의한 문제라고 하며 현업에서 흔히 마주칠 수 있는 문제 상황입니다. \\\n","이러한 부분을 어떻게 해결하여 성능을 올릴 수 있을지 고민해봅시다. \\\n","\n","(Hint Keyword) Imbalanced data \\\n","(Hint) 각 class 별로 loss 의 비중을 다르게 줄 수 있는 방법을 고민해봅시다 \n","\n","\n","### 8. 평가\n","\n","#### 기본 모델 구현 성공 (6점)\n","- meanIoU 함수 구현\n","- model save 구현\n","- save 한 model parameter 를 load 하여 test 성능을 확인하는 코드 구현\n","- 성공 예시 Visualization \n","\n","각 항목 당 미달 시 -1점\n","\n","#### 성능 향상에 따른 가산점\n","- 기본적인 semantic segmentation model 학습 성공 (7점)\n","- miou 0.66 이상 (8점)\n","- miou 0.68 이상 (9점)\n","- (Advanced) miou 0.69 이상, iou_scratch 0.40 이상 (10점)"]},{"cell_type":"markdown","metadata":{"id":"PkLvy-hKG-VA"},"source":["### Drive mount and package import"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"d2PPlRpblu2z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655530434917,"user_tz":-540,"elapsed":20421,"user":{"displayName":"김범중","userId":"05610879659513136687"}},"outputId":"574719c5-173f-4432-b3fc-9416d8c037e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"hADtuqTop7Wz","executionInfo":{"status":"ok","timestamp":1655530480692,"user_tz":-540,"elapsed":2530,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["import os\n","import time\n","import random\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","import torch.utils.data\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import random_split\n","\n","import torchvision\n","from torchvision import datasets, transforms\n","import torchvision.models as models\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"E738F-qolu24","executionInfo":{"status":"ok","timestamp":1655530480693,"user_tz":-540,"elapsed":8,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["# data 경로 설정 \n","# root = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"Colab Notebooks\", \"data\")\n","root = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"프로그래밍_교육\", \"쏘카 ai 엔지니어 육성 부트캠프 2기\", \"강의\", \"data\")"]},{"cell_type":"markdown","metadata":{"id":"amNT58iAS434"},"source":["### Dataset 준비\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2Ndo5JDuS436","executionInfo":{"status":"ok","timestamp":1655530480693,"user_tz":-540,"elapsed":6,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["class SOCAR_Dataset(torch.utils.data.Dataset):\n","    def __init__(self, root, transforms=None):\n","        self.root = root\n","        self.transforms = transforms\n","        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n","        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n","        \n","        \n","    def __getitem__(self, idx):\n","        # load images ad masks\n","        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n","        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n","        img = Image.open(img_path).convert(\"RGB\")\n","        mask = Image.open(mask_path)\n","\n","        mask = np.array(mask)[:,:,0]      # 3차원으로 구성된 mask 를 label 로 쓰기 위해 변환\n","\n","        mask[mask > 0] = 1\n","\n","        # there is only one class\n","        mask = torch.as_tensor(mask, dtype=torch.uint8)\n","\n","        target = {}\n","        target[\"masks\"] = mask\n","\n","        if self.transforms is not None:\n","            img, target = self.transforms(img, target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.imgs)"]},{"cell_type":"markdown","metadata":{"id":"YUatveWKuvsg"},"source":["### Transforms\n","원하는대로 transform 을 수정하거나 추가해봅시다!"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"bcr7b9ON9v2x","executionInfo":{"status":"ok","timestamp":1655530482628,"user_tz":-540,"elapsed":6,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["class RandomHorizontalFlip(object):\n","    def __init__(self, prob):\n","        self.prob = prob\n","\n","    def __call__(self, image, target):\n","        if random.random() < self.prob:\n","            height, width = image.shape[-2:]\n","            image = image.flip(-1)\n","            if \"masks\" in target:\n","                target[\"masks\"] = target[\"masks\"].flip(-1)\n","        return image, target\n","\n","\n","class ToTensor(object):\n","    def __call__(self, image, target):\n","        image = transforms.ToTensor()(image)\n","        return image, target\n","\n","class Resize(object):\n","    def __init__(self, size):\n","        self.size = size\n","    def __call__(self, image, target):\n","        image = transforms.Resize(self.size)(image)\n","        if \"masks\" in target:\n","            target[\"masks\"] = transforms.Resize(self.size)(target[\"masks\"].unsqueeze(dim=0)).squeeze()\n","        return image, target\n","\n","class Normalize(object):\n","    def __call__(self, image, target):\n","        image = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))(image)\n","        return image, target\n","\n","class Compose(object):\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, image, target):\n","        for t in self.transforms:\n","            image, target = t(image, target)\n","        return image, target"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zrSKFXDHBA9t","executionInfo":{"status":"ok","timestamp":1655530482629,"user_tz":-540,"elapsed":6,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["def get_transform(train):\n","    transforms = [ToTensor(), Resize((300,300)), Normalize()]\n","    if train:\n","        transforms.append(RandomHorizontalFlip(0.5))\n","    return Compose(transforms)"]},{"cell_type":"markdown","metadata":{"id":"wheHUeO2u3I2"},"source":["### Model\n","학습 모델을 정의해봅시다.\n","기본적인 목표는 pytorch pretrained model 을 불러오고 fine-tuning 을 위해 모델을 수정하는 것을 구현하는 것입니다.\n","#### (Optional)\n","직접 모델을 설계하고 구현해서 더 높은 성능을 내는 것도 도전해봅시다!\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"tEsXhMPH4eRr","scrolled":true,"executionInfo":{"status":"ok","timestamp":1655530487970,"user_tz":-540,"elapsed":350,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["##########################\n","#                        #\n","#         TO DO          #\n","#                        #\n","##########################"]},{"cell_type":"markdown","metadata":{"id":"7uVxrVTMvFii"},"source":["### Dataset split, DataLoader"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"94bE6US1w6M4","executionInfo":{"status":"ok","timestamp":1655530500397,"user_tz":-540,"elapsed":10850,"user":{"displayName":"김범중","userId":"05610879659513136687"}}},"outputs":[],"source":["# dent_train = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/train'), get_transform(train=True))\n","# dent_valid = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/valid'), get_transform(train=False))\n","# dent_test = SOCAR_Dataset(os.path.join(root,'accida_segmentation_dataset_v1/scratch_small/test'), get_transform(train=False))\n","dent_train = SOCAR_Dataset(os.path.join(root,'scratch_small/train'), get_transform(train=True))\n","dent_valid = SOCAR_Dataset(os.path.join(root,'scratch_small/valid'), get_transform(train=False))\n","dent_test = SOCAR_Dataset(os.path.join(root,'scratch_small/test'), get_transform(train=False))\n","\n","\n","train_loader = DataLoader(dent_train, batch_size=2, shuffle=True, drop_last=True)\n","valid_loader = DataLoader(dent_valid, batch_size=2, shuffle=False, drop_last=True)\n","test_loader = DataLoader(dent_test, batch_size=2, shuffle=False, drop_last=True)\n"]},{"cell_type":"markdown","metadata":{"id":"36oCr-8bvQnV"},"source":["### Trainer class 정의"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"AbGXbbNHK1iU","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"error","timestamp":1655530504884,"user_tz":-540,"elapsed":847,"user":{"displayName":"김범중","userId":"05610879659513136687"}},"outputId":"2795de62-ee15-4914-827e-3addc2a259f2"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-798bf5bcbc6e>\"\u001b[0;36m, line \u001b[0;32m290\u001b[0m\n\u001b[0;31m    iou = # TODO\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["## Trainer class 정의\n","\n","class Semantic_Seg_Trainer(nn.Module):\n","    def __init__(self, model,opt=\"adam\", num_class=2, lr=0.001, has_scheduler=False, device=\"cpu\", log_dir=\"./logs\", max_epoch=10):\n","        \"\"\"\n","          Args:\n","            model: 사용할 model\n","            opt: optimizer\n","            lr: learning rate\n","            has_scheduler: learning rate scheduler 사용 여부\n","            device: 사용할 device (cpu/cuda)\n","        \"\"\"\n","        super().__init__()\n","        \n","        self.max_epoch = max_epoch\n","        self.model = model                            \n","        self.loss = nn.CrossEntropyLoss()             # loss function 정의\n","        self.num_class = num_class\n","\n","        self._get_optimizer(opt=opt.lower(), lr=lr)   # optimizer 정의\n","        self.has_scheduler = has_scheduler            # scheduler 사용여부 \n","        if self.has_scheduler:\n","            self._get_scheduler()\n","\n","        self.device = device                          # 사용할 device\n","        \n","        self.log_dir = log_dir\n","        if not os.path.exists(log_dir): os.makedirs(log_dir)\n","\n","    def _get_optimizer(self, opt, lr=0.001):\n","        \"\"\"\n","          Args:\n","            opt: optimizer\n","            lr: learning rate\n","        \"\"\"\n","        if opt == \"sgd\":\n","            self.optimizer = torch.optim.SGD(params=self.model.parameters(), lr=lr)\n","        elif opt == \"adam\":\n","            self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=lr)\n","        else:\n","            raise ValueError(f\"optimizer {opt} is not supproted\")\n","\n","    def _get_scheduler(self):\n","        self.scheduler = torch.optim.lr_scheduler.StepLR(optimizer=self.optimizer, step_size=5, gamma=0.5, verbose=True)\n","\n","    def train(self, train_loader, valid_loader, max_epochs=10, disp_step=1, visualize=False):\n","        \"\"\"\n","          네트워크를 학습시키는 함수\n","          Args:\n","            train_loader: 학습에 사용할 train dataloader\n","            valid_loader: validation에 사용할 dataloader\n","            max_epochs: 학습을 진행할 총 epoch 수\n","            disp_epochs: 학습 log를 display 할 epoch 주기\n","            visualize: 학습 진행 과정에서 결과 이미지를 visualize \n","        \"\"\"\n","        print(\"===== Train Start =====\")\n","        start_time = time.time()   \n","        history = {\"train_loss\": [], \"valid_loss\": [], \"train_miou\": [], \"valid_miou\": []}\n","        \n","        for e in range(max_epochs):\n","            print(f\"Start Train Epoch {e}\")\n","            train_loss, train_miou = self._train_epoch(train_loader)\n","            print(f\"Start Valid Epoch {e}\")\n","            valid_loss, valid_miou = self._valid_epoch(valid_loader)\n","            \n","            \n","            history[\"train_loss\"].append(train_loss)      # 현재 epoch에서 성능을 history dict에 저장\n","            history[\"valid_loss\"].append(valid_loss)      #\n","            \n","            history[\"train_miou\"].append(train_miou)      # \n","            history[\"valid_miou\"].append(valid_miou)      #\n","\n","            if self.has_scheduler:         # scheduler 사용할 경우 step size 조절\n","                self.scheduler.step()\n","\n","            if e % disp_epoch == 0:        # disp_epoch 마다 결과값 출력 \n","                print(f\"Epoch: {e}, train loss: {train_loss:>6f}, valid loss: {valid_loss:>6f}, train miou: {train_miou:>6f}, valid miou: {valid_miou:>6f}, time: {time.time()-start_time:>3f}\")\n","                \n","                start_time = time.time()   \n","\n","            self.plot_history(history, save_name=f\"{self.log_dir}/log_epoch_{e}.png\")       # 그래프 출력\n","            #################################################################################################\n","            #                                                                                               #\n","            # TODO : 한 epoch 의 학습이 끝날때 마다 model 을 save 하는 코드를 작성해봅시다.                 #\n","            #        graph 저장 코드를 참고하여 저장되는 model 의 이름에 몇 epoch 인지 나타나게 해봅시다.   # \n","            #                                                                                               #\n","            #################################################################################################\n","\n","    def _train_epoch(self, train_loader, disp_step=10):\n","        \"\"\"\n","          model를 training set 한 epoch 만큼 학습시키는 함수\n","          Args:\n","            train_loader: 학습에 사용할 train dataloader\n","          Returns:\n","            training set 한 epoch의 평균 loss, 평균 accuracy\n","        \"\"\"\n","        epoch_loss = 0\n","        \n","        miou = 0\n","        ious = np.zeros([2])\n","        \n","        self.model.train()                 # self.model을 train 모드로 전환 --> nn.Module의 내장함수\n","        cnt = 0\n","        epoch_start_time = time.time()\n","        start_time = time.time()\n","        for (x, y) in train_loader:        # x: data, y:label\n","            cnt += 1\n","\n","            x = x.to(self.device)\n","            label = y['masks'].to(self.device).type(torch.long)\n","            \n","            out = self.model(x)              # model이 예측한 output\n","            loss = self.loss(out['out'], label)       \n","\n","            self.optimizer.zero_grad()       # backwardpass를 통한 network parameter 업데이트\n","            loss.backward()                  # \n","            self.optimizer.step()            # \n","            \n","            epoch_loss += loss.to(\"cpu\").item()    \n","            \n","            out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)           # meanIoU 계산을 위한 데이터 변형\n","            out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)               #\n","            \n","            ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long)) # ious[0]:background IoU\n","            ious[1] += self.batch_segmentation_iou(out_target, label)                                         # ious[1]:파손 IoU\n","            \n","            if cnt % disp_step == 0:\n","                iou_back = ious[0]/(cnt*x.shape[0])\n","                iou_scratch = ious[1]/(cnt*x.shape[0])\n","                miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","                \n","                print(f\"Iter: {cnt}/{len(train_loader)}, train epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n","                start_time = time.time()   \n","\n","        epoch_loss /= len(train_loader)  \n","        \n","        \n","        iou_back = ious[0]/(cnt*x.shape[0])\n","        iou_scratch = ious[1]/(cnt*x.shape[0])\n","        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","        print(f\"Train loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n","\n","        return epoch_loss, epoch_miou\n","  \n","    def _valid_epoch(self, valid_loader, disp_step=10):\n","        \"\"\"\n","          현재 model의 성능을 validation set에서 측정하는 함수\n","          Args:\n","            valid_loader: 학습에 사용할 valid dataloader\n","          Returns:\n","            validation set 의 평균 loss, 평균 accuracy\n","        \"\"\"\n","        epoch_loss = 0\n","        \n","        miou = 0\n","        ious = np.zeros([2])\n","                      \n","        self.model.eval()                  # self.model을 eval 모드로 전환 --> nn.Module의 내장함수\n","        cnt = 0\n","        epoch_start_time = time.time()\n","        start_time = time.time()\n","        with torch.no_grad():              # model에 loss의 gradient를 계산하지 않음\n","            for (x, y) in valid_loader:\n","                cnt += 1\n","                x = x.to(self.device)\n","                label = y['masks'].to(self.device).type(torch.long)\n","\n","                out = self.model(x) \n","                loss = self.loss(out['out'], label)\n","                      \n","                epoch_loss += loss.to(\"cpu\").item()\n","                \n","                out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)\n","                out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)\n","\n","                ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long))\n","                ious[1] += self.batch_segmentation_iou(out_target, label)\n","                    \n","\n","                \n","                \n","                if cnt % disp_step == 0:\n","                    iou_back = ious[0]/(cnt*x.shape[0])\n","                    iou_scratch = ious[1]/(cnt*x.shape[0])\n","                    miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","                    print(f\"Iter: {cnt}/{len(valid_loader)}, valid epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n","                    start_time = time.time()   \n","\n","        epoch_loss /= len(valid_loader)\n","        \n","        iou_back = ious[0]/(cnt*x.shape[0])\n","        iou_scratch = ious[1]/(cnt*x.shape[0])\n","        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","        print(f\"Valid loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n","\n","        return epoch_loss, epoch_miou\n","\n","    def plot_history(self, history, save_name=None):\n","        \"\"\"\n","          history에 저장된 model의 성능을 graph로 plot\n","          Args:\n","            history: dictionary with keys {\"train_loss\",\"valid_loss\",  }\n","                     각 item 들은 epoch 단위의 성능 history의 list\n","        \"\"\"\n","        fig = plt.figure(figsize=(16, 8))\n","        \n","        \n","        ax = fig.add_subplot(1, 2, 1)\n","        ax.plot(history[\"train_loss\"], color=\"red\", label=\"train loss\")\n","        ax.plot(history[\"valid_loss\"], color=\"blue\", label=\"valid loss\")\n","        ax.title.set_text(\"Loss\")\n","        ax.legend()\n","        \n","        ax = fig.add_subplot(1, 2, 2)\n","        ax.plot(history[\"train_miou\"], color=\"red\", label=\"train miou\")\n","        ax.plot(history[\"valid_miou\"], color=\"blue\", label=\"valid miou\")\n","        ax.title.set_text(\"miou\")\n","        ax.legend()\n","\n","        plt.show()\n","                      \n","        if not save_name == None:     # graph 저장\n","            plt.savefig(save_name)\n","                      \n","        \n","\n","    def test(self, test_loader):\n","        \"\"\"\n","          현재 model의 성능을 test set에서 측정하는 함수\n","          Args:\n","            test_loader: 학습에 사용할 test dataloader\n","          Returns:\n","            test set 의 평균 loss, 평균 accuracy\n","        \"\"\"\n","        print(\"===== Test Start =====\")\n","        start_time = time.time()\n","        epoch_loss = 0\n","        \n","        miou = 0\n","        ious = np.zeros([2])\n","                      \n","        self.model.eval()                  # self.model을 eval 모드로 전환 --> nn.Module의 내장함수\n","        cnt = 0\n","        epoch_start_time = time.time()\n","        start_time = time.time()\n","        with torch.no_grad():              # model에 loss의 gradient를 계산하지 않음\n","            for (x, y) in test_loader:\n","                cnt += 1\n","                x = x.to(self.device)\n","                label = y['masks'].to(self.device).type(torch.long)\n","\n","                out = self.model(x) \n","                loss = self.loss(out['out'], label)\n","\n","                epoch_loss += loss.to(\"cpu\").item()\n","                      \n","                out_background = torch.argmin(out['out'].to(\"cpu\"), dim=1).to(self.device)\n","                out_target = torch.argmax(out['out'].to(\"cpu\"), dim=1).to(self.device)\n","\n","                ious[0] += self.batch_segmentation_iou(out_background, torch.logical_not(label).type(torch.long))\n","                ious[1] += self.batch_segmentation_iou(out_target, label)\n","                \n","                if cnt % 10 == 0:\n","                    iou_back = ious[0]/(cnt*x.shape[0])\n","                    iou_scratch = ious[1]/(cnt*x.shape[0])\n","                    miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","                    print(f\"Iter: {cnt}/{len(valid_loader)}, test epcoh loss: {epoch_loss/(cnt):>6f}, miou: {miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-start_time:>3f}\")\n","                    start_time = time.time()  \n","\n","        epoch_loss /= len(test_loader)\n","        \n","        \n","        iou_back = ious[0]/(cnt*x.shape[0])\n","        iou_scratch = ious[1]/(cnt*x.shape[0])\n","        epoch_miou = (ious[0]/(cnt*x.shape[0]) + ious[1]/(cnt*x.shape[0])) / 2.\n","        \n","        print(f\"Test loss: {epoch_loss:>6f}, miou: {epoch_miou:>6f}, iou_back : {iou_back:>6f}, iou_scratch : {iou_scratch:>6f}, time: {time.time()-epoch_start_time:>3f}\")\n","\n","    \n","    def batch_segmentation_iou(self, outputs, labels):\n","        \"\"\"\n","            outputs, labels : (batch, h, w)\n","        \"\"\"\n","        \n","        SMOOTH = 1e-6\n","\n","        intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n","        union = (outputs | labels).float().sum((1, 2))         # Will be zero if both are 0\n","\n","        iou = # TODO\n","        \n","        #################################################################################################\n","        #                                                                                               #\n","        # TODO : 위 코드를 보고 IoU 를 계산하는 코드를 만들어봅시다.                                    #\n","        # hint : 나누기에서 0으로 나누면 error 가 발생하기 때문에 이를 피하기 위해 분자와 분모에        #\n","        #        아주 작은 수인 SMOOTH 를 더해줍시다                                                    #\n","        #        ex) x / y   --->   (x + SMOOTH) / (y + SMOOTH)                                         #\n","        #                                                                                               #\n","        #################################################################################################\n","        \n","        \n","        return torch.sum(iou).to(\"cpu\").numpy()"]},{"cell_type":"markdown","metadata":{"id":"I0QATJWUvVys"},"source":["### Fine-tuning\n","device 를 gpu 로 설정하고 trainer를 정의해봅시다.\n","정의된 trainer 와 train, valid 데이터로 모델을 학습을 시켜봅시다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmK6tKmtMe0i"},"outputs":[],"source":["#################################################################################################\n","#                                                                                               #\n","# TODO : trainer 를 정의해봅시다.                                                               #\n","#                                                                                               #\n","#################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xudsbSMlu3P","scrolled":false},"outputs":[],"source":["start_time = time.time()\n","trainer.train(train_loader, valid_loader, max_epochs=10, disp_step=1)\n","print(f\"Training time : {time.time()-start_time:>3f}\")"]},{"cell_type":"markdown","metadata":{"id":"F9WeG-kkvZ9q"},"source":["### Fine-tuning 결과 테스트\n","학습된 모델 parameter 를 load 하여 test 성능을 확인해보고 test set 에서 좋은 예시를 찾아서 visualize 해봅시다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVhe8PAblu3P"},"outputs":[],"source":["#################################################################################################\n","#                                                                                               #\n","# TODO : save 한 model parameter 를 load 하여 test set 에서 성능을 확인해봅시다.                #\n","#                                                                                               #\n","#################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bv3nlpbJQcvu"},"outputs":[],"source":["image = Image.open(os.path.join(root,'좋은 example'))\n","mask = Image.open(os.path.join(root,'좋은 example'))\n","\n","\n","infer_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])\n","\n","input_image = infer_transform(image).to(device)\n","\n","output = seg_model(input_image.unsqueeze(dim=0))\n","output['out'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lo53zJ4IRsxD"},"outputs":[],"source":["#################################################################################################\n","#                                                                                               #\n","# TODO : [ 이미지, ground truth, prediction ] 을 가로로 나란히 subplot 해봅시다.                #\n","#                                                                                               #\n","#################################################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vhUQcaRlu3Q"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Assignment_3_Semantic+Segmentation+finetuning.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"socar","language":"python","name":"socar"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":0}